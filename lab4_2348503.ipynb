{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aleena24/ML_Lab/blob/main/lab4_2348503.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CMY7m7csn2hY"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import threading\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import logging\n",
        "import queue\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CrYEku6epyjU"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/Groceries_dataset.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRT8ZSqM0d9C"
      },
      "source": [
        "Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "got5eR3sqSYB"
      },
      "outputs": [],
      "source": [
        "#identifying the datatype\n",
        "print(df.dtypes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Obzu58UnuRP_"
      },
      "outputs": [],
      "source": [
        "def fp_growth(dataset):\n",
        "\n",
        "  fp_growth_format = []\n",
        "  for transaction in dataset:\n",
        "    new_transaction = []\n",
        "    for item in transaction:\n",
        "      try:\n",
        "        new_transaction.append(int(item))\n",
        "      except ValueError:\n",
        "        # The item is not an integer, so we skip it.\n",
        "        continue\n",
        "    fp_growth_format.append(new_transaction)\n",
        "\n",
        "  return fp_growth_format\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "umcojegRunr9"
      },
      "outputs": [],
      "source": [
        "dataset = [[\"a\", \"b\", \"c\"], [\"b\", \"c\", \"d\"], [\"a\", \"b\"]]\n",
        "\n",
        "fp_growth_format = fp_growth(dataset)\n",
        "\n",
        "print(fp_growth_format)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I3HypT-a0hEX"
      },
      "outputs": [],
      "source": [
        "def apriori_format(dataset):\n",
        "\n",
        "  apriori_format = []\n",
        "  for transaction in dataset:\n",
        "    new_transaction = []\n",
        "    for item in transaction:\n",
        "      new_transaction.append(str(item))\n",
        "    apriori_format.append(new_transaction)\n",
        "\n",
        "  return apriori_format\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Grjs5VmT08Hb"
      },
      "source": [
        "Multithreading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C3ulFfbN0_XY"
      },
      "outputs": [],
      "source": [
        "def my_function_1():\n",
        "  print(\"Thread for FP Growth\")\n",
        "\n",
        "def my_function_2():\n",
        "  print(\"Thread for Apriori Algorithm\")\n",
        "\n",
        "thread_1 = threading.Thread(target=my_function_1, daemon = True)\n",
        "thread_2 = threading.Thread(target=my_function_2, daemon = True)\n",
        "# Daemon threads are threads that are not required to finish before the main thread exits.\n",
        "\n",
        "thread_1.start()\n",
        "thread_2.start()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnXnqgHf4MnU"
      },
      "source": [
        "Algorithm Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V5-MkiD44QBp"
      },
      "outputs": [],
      "source": [
        "def fp_growth(dataset, min_support, confidence):\n",
        "\n",
        "  fp_tree = FPTree(dataset, min_support)\n",
        "  frequent_item_sets = fp_tree.mine()\n",
        "\n",
        "  for item_set in frequent_item_sets:\n",
        "    for item in item_set:\n",
        "      if len(item_set) > 1:\n",
        "        confidence = fp_tree.get_confidence(item_set, item)\n",
        "        if confidence >= confidence:\n",
        "          frequent_item_sets.append([item])\n",
        "\n",
        "  return frequent_item_sets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MyzPWjiH45mg"
      },
      "outputs": [],
      "source": [
        "class Apriori:\n",
        "\n",
        "  def __init__(self, min_support, confidence):\n",
        "    self.min_support = min_support\n",
        "    self.confidence = confidence\n",
        "    self.frequent_item_sets = []\n",
        "\n",
        "  def mine(self, dataset):\n",
        "\n",
        "    item_sets = self._generate_candidate_item_sets(1)\n",
        "\n",
        "    while len(item_sets) > 0:\n",
        "      frequent_item_sets = self._mine_item_sets(dataset, item_sets, self.min_support)\n",
        "      item_sets = self._generate_candidate_item_sets(len(frequent_item_sets[0]))\n",
        "\n",
        "    return frequent_item_sets\n",
        "\n",
        "  def _generate_candidate_item_sets(self, k):\n",
        "\n",
        "    candidate_item_sets = []\n",
        "\n",
        "    for item_set in self.frequent_item_sets:\n",
        "      for item in dataset:\n",
        "        if item not in item_set:\n",
        "          candidate_item_set = item_set + [item]\n",
        "          if len(candidate_item_set) == k:\n",
        "            candidate_item_sets.append(candidate_item_set)\n",
        "\n",
        "    return candidate_item_sets\n",
        "\n",
        "  def _mine_item_sets(self, dataset, item_sets, min_support):\n",
        "\n",
        "    frequent_item_sets = []\n",
        "\n",
        "    for item_set in item_sets:\n",
        "      support = self._get_support(dataset, item_set)\n",
        "      if support >= min_support:\n",
        "        frequent_item_sets.append(item)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWpNP7s17fqs"
      },
      "source": [
        "Parallel Execution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2l4S0ikfMxJ",
        "outputId": "eb2ed54d-0fa3-4aa7-9f20-8b03e5f1c7a0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception in thread Thread-12 (fp_algorithm):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "Exception in thread Thread-13 (apriori_algorithm):\n",
            "Traceback (most recent call last):\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self._target(*self._args, **self._kwargs)    \n",
            "  File \"<ipython-input-10-8349491317f3>\", line 3, in fp_algorithm\n",
            "self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-10-8349491317f3>\", line 10, in apriori_algorithm\n",
            "TypeError: Apriori.__init__() takes 3 positional arguments but 4 were given\n",
            "  File \"<ipython-input-8-3459a0ffcd2e>\", line 3, in fp_growth\n",
            "NameError: name 'FPTree' is not defined. Did you mean: 'fp_tree'?\n"
          ]
        }
      ],
      "source": [
        "def fp_algorithm(df, min_support=0.05, confidence=0.8):\n",
        "  start_time = time.time()\n",
        "  frequent_itemsets = fp_growth(df, min_support, confidence)\n",
        "  end_time = time.time()\n",
        "  fp_execution_time = end_time - start_time\n",
        "  return fp_execution_time\n",
        "\n",
        "def apriori_algorithm(df, min_support=0.05, confidence=0.8):\n",
        "  start_time = time.time()\n",
        "  frequent_itemsets = Apriori(df, min_support, confidence)\n",
        "  end_time = time.time()\n",
        "  apriori_execution_time = end_time - start_time\n",
        "  return apriori_execution_time\n",
        "\n",
        "  # Create a queue to store the execution times of the two algorithms\n",
        "queue = queue.Queue()\n",
        "\n",
        "def main():\n",
        "  # Load the inbuilt dataset\n",
        "  data = pd.read_csv(\"Groceries_dataset.csv\", header=None)\n",
        "\n",
        "  # Create threads for the FP and Apriori algorithms\n",
        "  fp_thread = threading.Thread(target=fp_algorithm, args=(df,))\n",
        "  apriori_thread = threading.Thread(target=apriori_algorithm, args=(df,))\n",
        "\n",
        "  # Start the threads\n",
        "  fp_thread.start()\n",
        "  apriori_thread.start()\n",
        "\n",
        "  # Wait for the threads to finish\n",
        "  fp_thread.join()\n",
        "  apriori_thread.join()\n",
        "\n",
        "  # Get the execution times of the two algorithms\n",
        "  fp_execution_time = queue.get()\n",
        "  apriori_execution_time = queue.get()\n",
        "\n",
        "  # Print the execution times\n",
        "  print(\"FP-growth algorithm execution time:\", fp_execution_time)\n",
        "  print(\"Apriori algorithm execution time:\", apriori_execution_time)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTzU1PwzhzP6"
      },
      "source": [
        "Data Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HE-KUUchhy1X"
      },
      "outputs": [],
      "source": [
        "  # Create a bar chart of the execution times\n",
        "  x = [\"FP-growth\", \"Apriori\"]\n",
        "  y = [fp_execution_time, apriori_execution_time]\n",
        "  plt.bar(x, y)\n",
        "  plt.xlabel(\"Algorithm\")\n",
        "  plt.ylabel(\"Execution time (seconds)\")\n",
        "  plt.title(\"Comparison of FP-growth and Apriori execution times\")\n",
        "  plt.show()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onwVXtKerdpu"
      },
      "source": [
        "Recommendation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V5rJOFIKrh7p"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "maK_H0Rp31QN"
      },
      "source": [
        "Bonus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zuW-qcPo33dU"
      },
      "outputs": [],
      "source": [
        "def mine_association_rules(frequent_itemsets, min_support, min_confidence):\n",
        "  association_rules = []\n",
        "  for itemset in frequent_itemsets:\n",
        "    for subset in itemset:\n",
        "      if len(subset) > 1:\n",
        "        confidence = len(itemset) / len(subset)\n",
        "        if confidence >= min_confidence:\n",
        "          association_rules.append((subset, itemset - subset, confidence))\n",
        "  return association_rules\n",
        "\n",
        "def main():\n",
        "  data = read_data()\n",
        "\n",
        "  # Get the minimum support and minimum confidence thresholds from the user\n",
        "  min_support = float(input(\"Enter the minimum support threshold: \"))\n",
        "  min_confidence = float(input(\"Enter the minimum confidence threshold: \"))\n",
        "\n",
        "  # Mine association rules from the frequent itemsets generated by both algorithms\n",
        "  fp_frequent_itemsets = fp_algorithm(data)\n",
        "  apriori_frequent_itemsets = apriori(data)\n",
        "\n",
        "  fp_association_rules = mine_association_rules(fp_frequent_itemsets, min_support, min_confidence)\n",
        "  apriori_association_rules = mine_association_rules(apriori_frequent_itemsets, min_support, min_confidence)\n",
        "\n",
        "  # Print the association rules generated by both algorithms\n",
        "  print(\"FP-growth algorithm\")\n",
        "  for rule in fp_association_rules:\n",
        "    print(rule)\n",
        "\n",
        "  print(\"Apriori algorithm\")\n",
        "  for rule in apriori_association_rules:\n",
        "    print(rule)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPr7e4ZYKPRxMcGGpozjgaE",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}